{"pageProps":{"postData":{"frontmatter":{"title":"Return & Volatility of a multi asset portfolio","description":"Maths are magical :) And why diversification makes sense!","date":"January 31, 2021","topic":{"id":"investing","name":"Investing","image":"investing.png","description":"The piggy bank digests a good amount of the savings! There is only one way to get away ... investing. BUT, there is a hidden enemy, Speculation!","color":"bg-green-300"},"tags":[{"id":"statistics","name":"statistics","image":"statistics.jpg","description":"Statistics is the discipline that concerns the collection, organization, analysis, interpretation and presentation of data. - Wikipedia","color":"bg-green-300","icon":"statistics.svg"}],"author":{"id":"chris","name":"Chris","image":"https://s.gravatar.com/avatar/db809ecfa64d56da4bd9704c8393005a?s=80","description":"Software Engineer, passionate about ..."},"img":"/static/magic.png","colab":"https://colab.research.google.com/drive/1lNirrCFUfWaZ_Cci-mmsio79wX_KwR5b?usp=sharing"},"post":{"content":"\nIn previous posts we talked about the [expected return](/post/measures-of-location) (mean value of a distribution) and the [volatility](/post/measures-of-variability) (standard deviation) of an asset.\n\nBut, in investing, we rarely hold a portfolio of just one stock! Let's start then, by picking two stocks.\n\nThe first question is: OK, what percentage of the total investment amount shall we allocate to stock A and what to stock B?\n\nIf we allocate 100% to A and 0% to B or the other way around, then we get into the \"one asset\" portfolio and that is not desirable! Let's assume that we set 50% on asset A and 50% on asset B. Let's also call this percentage allocations, weights (w_A, w_B respectively).\n\nIn that case, we are asked to come up with the return (mean) and the volatility (standard deviation) of the portfolio.\n\nSomeone would blindly assume that the `Return = (w_A * R_A) + (w_B * R_B)` and `Volatility = (w_A * std_A) + (w_B * std_B)`. Well, maths keep always surprising us, and that is the case here!\n\nWhile indeed the return of the 2 asset portfolio is the average weighted returns,\n\n$$\nR_{A,B} = w_A*R_A + w_B*R_B  \\qquad (1)\n$$\n\nthe volatility is\n\n$$\n\\sigma_{A,B}=\\sqrt{\\sigma_A^2w_A^2 + \\sigma_B^2w_B^2 + 2w_Aw_B\\sigma_A\\sigma_B\\rho_{A,B}}  \\quad (2)\n$$\n\nThis second (2) equation tells us that the standard deviation of a 2 asset distribution is equal to the square root of the variance of asset A multiplied by the squared weight of A plus the variance of asset B multiplied by the squared weight of B, plus twice the product of variance of A times the variance of B times the weight of A times the weight of B times the correlation coefficient of A and B!\n\nSo far so good! But where exactly does the magic begin? Well, the correlation coefficient is not always a positive number :O\n\nThe correlation coefficient can take values between -1 and 1. -1 when the two assets are totally uncorrelated, which means that when the first asset goes up the other goes down at the same pace and same angle. 1 when both assets move to the same direction with the same pace and same angle (either positive or negative direction). Values between -1 and 1 indicate a more loose correlation, but show the trend.\n\nBack to the equation (2). If we have a negative correlation of the assets, the total volatility is less than the average volatility, and if we have a positive correlation the total volatility is more that the average.\n\nIt becomes pretty obvious that by just combining two non correlated assets we can achieve volatility sometimes even smaller than the assets' individually. Who wouldn't want that!\n\n> Keep in mind that $\\rho_{A,B} = \\frac{cov_{A,B}}{\\sigma_A\\sigma_B}$ where $cov_{A,B}$ is the covariance of the two variables.\n\nLet's see an example...\n\n## Real example of a two asset portfolio\n\nAt first, let's set the ground work to be able to fetch some stock prices.\n\n```\n%pip install yahoofinancials\nfrom yahoofinancials import YahooFinancials\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport dateutil.parser\nimport numpy as np\n\ndef retrieve_stock_data(ticker, start, end):\n    json = YahooFinancials(ticker).get_historical_price_data(start, end, \"daily\")\n    columns=[\"adjclose\"]  # [\"open\",\"close\",\"adjclose\"]\n    df = pd.DataFrame(columns=columns)\n    for row in json[ticker][\"prices\"]:\n        d = dateutil.parser.isoparse(row[\"formatted_date\"])\n        df.loc[d] = [row[\"adjclose\"]] # [row[\"open\"], row[\"close\"], row[\"adjclose\"]]\n    df.index.name = \"date\"\n    return df\n\ndef normal_rets(S):\n    return S.pct_change().dropna()\n```\n\nWe are now ready to fetch prices. I have picked Microsoft Corporation (MSFT) and Alpha Pro Tech, Ltd. (APT). Below we see how the price of the stocks unfolded throughout 2020! \n\n```\nmsft_stock_prices = retrieve_stock_data(\"MSFT\", \"2020-01-01\", \"2021-01-01\")\nmsft_rets = normal_rets(msft_stock_prices).dropna()\nmsft_rets.columns = ['returns']\n\napt_stock_prices = retrieve_stock_data(\"APT\", \"2020-01-01\", \"2021-01-01\")\napt_rets = normal_rets(apt_stock_prices).dropna()\napt_rets.columns = ['returns']\n\nf, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\nmsft_stock_prices.plot(figsize=(14,7), ax=ax1)\napt_stock_prices.plot(figsize=(14,7), ax=ax2)\nax1.get_legend().remove()\nax2.get_legend().remove()\nax1.title.set_text('MSFT Price Chart')\nax2.title.set_text('APT Price Chart')\nplt.show()\n```\n\n![png](portfolio-expected-return-and-risk/portfolio-expected-return-and-risk_4_0.png)\n\nThe graphs show some king of un-correlation. When one stock goes up the other goes down and vice versa. Let's explore the average return, standard deviation and correlation of the stocks.\n\n```\nmsft_rets.mean().values[0], apt_rets.mean().values[0]\n```\n    (0.0017171460669071206, 0.009654517798428635)\n\n\n```\nmsft_rets.std().values[0], apt_rets.std().values[0]\n```\n    (0.027679154652983044, 0.10987021868530256)\n\n```\nreturns = msft_rets.merge(apt_rets, left_index=True, right_index=True)\nreturns.columns = ['MSFT', 'APT']\nreturns.corr()\n```\n\n<div>\n<table border=\"1\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSFT</th>\n      <th>APT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MSFT</th>\n      <td>1.0000</td>\n      <td>-0.2182</td>\n    </tr>\n    <tr>\n      <th>APT</th>\n      <td>-0.2182</td>\n      <td>1.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\nObviously, both stocks yield a positive average daily return (small but positive), and while MSFT has a volatility around ~2.8%, APT is at ~11%, which denotes a very volatile asset. As expected, the correlation of the two assets is negative.\n\nLet us now try to construct a portfolio of these two assets. From equations (1) and (2) we see that the weights are variable. We should also notice that the return is not a series of returns anymore but a single value. This value is the total return of an asset over the year. It is the so called [`Annualized Return`](/post/geometric-progression-and-compounding-of-returns).\n\n\n```\ndef annualize_rets(r, periods_per_year):\n    compounded_growth = (1+r).prod()\n    n_periods = r.shape[0]\n    return compounded_growth**(periods_per_year/n_periods)-1\n\nannualized_returns = annualize_rets(returns, 252)\nannualized_returns\n```\n\n    MSFT    0.399429\n    APT     2.222543\n    dtype: float64\n\n\nAs you can see the annual return for 2020 for MSFT was ~40%, while for APT was ~220%! It is pretty obvious from the price graphs :)\n\nNow, we move on and try to generate some portfolios where we assign different weights to the assets and try to calculate the return and the volatility of the portfolio. I will not get into what transposing a matrix means in algebra since it is not the focus of this post. Please check [this wikipedia article](https://en.wikipedia.org/wiki/Transpose) for more info.\n\n\n```\n# from equation (1)\ndef portfolio_return(weights, returns):\n    return weights.T @ returns\n\n# from equation (2)\ndef portfolio_vol(weights, covariance_matrix):\n    return (weights.T @ covariance_matrix @ weights)**0.5\n\n# first we construct 10 pairs of weights like [(0.1,0.9), (0.2,0.8) ...]\nweights = [np.array([w, 1-w]) for w in np.linspace(0, 1, 10)]\n\n# then we calculate the return of the portfolio for each pair of weights\nportfolio_returns = [portfolio_return(w, annualized_returns) for w in weights]\n\n# and the volatility of the portfolio for each pair of weights\nvols = [portfolio_vol(w, returns.cov()) for w in weights]\n\nef = pd.DataFrame({\n    \"Return\": portfolio_returns, \n    \"Volatility\": vols,\n    \"weights\": weights\n})\n\nax = ef.plot(x=\"Volatility\", y=\"Return\", style=\".-\", figsize=(11,6),\n             title=\"2 Asset Portfolio Risk/Return\", legend=False)\nplt.ylabel(\"Return\")\n\ndef label_point(x, y, val, ax):\n  a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n  for i, point in a.iterrows():\n    prettified_p = f\"({round(point['val'][0], 2)},{round(point['val'][1], 2)})\"\n    ax.text(point['x'], point['y'], prettified_p)\n\nlabel_point(ef.Volatility, ef.Return, ef.weights, ax)\n```\n  \n![png](portfolio-expected-return-and-risk/portfolio-expected-return-and-risk_12_0.png)\n\nWhat the graph above tells us is that by combining the two assets we are able to achieve a total volatility (risk) that is less than each asset's individual volatility!\n\nObserve the left most point on the graph!\n\nIn a next post we will calculate the optimal weights that minimize the risk of a portfolio as well as explore portfolios with more than 2 assets.\n\n## Some More Notes\n\n* The approach I followed above is not something new. Is called [Markowitz Model](https://en.wikipedia.org/wiki/Markowitz_model) and won a [Nobel Price](https://www.nobelprize.org/prizes/economic-sciences/1990/press-release/) in 1990.\n* I tried to oversimplify the example, just to show the basics.\n* I randomly picked the two assets, in the example, from [IMPACTOPIA](http://www.market-topology.com/correlation/MSFT?etf=0).\n* We will prove later on that volatility changes over time :) and that would normally lead to rebalances.\n* As always, `Historical returns are no guarantee of future returns.`\n\nStay tuned ...\n","excerpt":""},"previousPost":{"slug":"global-market-insights-after-the-pandemic","frontmatter":{"title":"Global Market Insights after the Pandemic.","description":"What are the projections after the Pandemic? Let's explore ...","date":"January 21, 2021","topic":{"id":"investing","name":"Investing","image":"investing.png","description":"The piggy bank digests a good amount of the savings! There is only one way to get away ... investing. BUT, there is a hidden enemy, Speculation!","color":"bg-green-300"},"tags":[{"id":"python","name":"python","image":"python-header.png","description":"Python is very handy in investing","color":"bg-green-300","icon":"python.svg"}],"author":{"id":"chris","name":"Chris","image":"https://s.gravatar.com/avatar/db809ecfa64d56da4bd9704c8393005a?s=80","description":"Software Engineer, passionate about ..."},"img":"/static/after-covid-19.jpeg","colab":"https://colab.research.google.com/drive/1nPyDupJHidnP5DLfAEKX3eYiY-MHCDmM?usp=sharing"},"excerpt":"","content":"\n2020 was a difficult year and most of the market segments diverged from the projections! With the new facts at hand, and the emerging needs after the pandemic, we should expect changes in the market.\n\nBelow is an attempt to get a feeling of the emerging sectors by analyzing some [Global Market Insights](https://www.gminsights.com/) reports.\n\nAnd as always, let's automate ...\n\n```\n!pip install requests beautifulsoup4\nimport requests\nimport re\nfrom bs4 import BeautifulSoup\nimport string\n\nclass GlobalMarketInsights:\n  __DEFAULT_BASE_URL = 'https://www.gminsights.com/industry-reports'\n  \n  @staticmethod\n  def _escape(input):\n    printable = string.ascii_letters + string.digits + string.punctuation + ' '\n    return ''.join(c if c in printable else ' ' for c in input )\n\n  def _description_matcher(self, descr):\n    descr = GlobalMarketInsights._escape(descr.replace('\\t', ' ').replace('\\n', ' ').replace('\\r', ' '))\n\n    start_date = end_date = percentage = market_name = None\n\n    r1 = re.search('^(.*) (?:Market|Aftermarket) .*$', descr, re.IGNORECASE)\n    if r1:\n      market_name = r1.group(1).strip()\n\n    r2 = re.search('.* between (\\d+) (?:and|to) (\\d+)', descr)\n    if r2:\n      start_date = r2.group(1).strip()\n      end_date = r2.group(2).strip()\n    \n    r3 = re.search('.* (?:from|of) (\\d+) to (\\d+)', descr)\n    if r3:\n      start_date = r3.group(1).strip()\n      end_date = r3.group(2).strip()\n    \n    r4 = re.search('([-+]?\\d*\\.\\d+|\\d+)%', descr)\n    if r4:\n      percentage = r4.group(1)\n    \n    if None in (market_name, percentage, start_date, end_date):\n      raise Exception(f\"Couldn't parse: {descr}\")\n    else:\n      return {\n        \"market\": market_name,\n        \"percentage\" : float(percentage),\n        \"start\": int(start_date),\n        \"end\": int(end_date)\n      }\n\n  def get(self, page=1):\n    page = requests.get(f\"{GlobalMarketInsights.__DEFAULT_BASE_URL}?page={page}\")\n    soup = BeautifulSoup(page.text, 'html.parser')\n    single_rds = soup.find_all('div', class_='single_rd')\n    reports = []\n    for single_rd in single_rds:\n      single_rd_children = single_rd.findChildren()\n      for single_rd_child in single_rd_children:\n        if single_rd_child.has_attr('class') and single_rd_child['class'][0] == 'rd_desc':\n          description = single_rd_child.getText()\n          try:\n            reports.append(self._description_matcher(description))\n          except Exception as e:\n            # print(e)\n            pass\n          break\n    return reports\n  \n  def fetch_all_reports(self):\n    # get the total number of pages and start iterating\n    page = requests.get(f\"{GlobalMarketInsights.__DEFAULT_BASE_URL}?page=1\")\n    lun_q = 'Displaying \\d+ records out of (\\d+) on Page \\d+ of (\\d+)'\n    r = re.search(lun_q, page.text)\n    if r:\n        number_of_records = r.group(1)\n        number_of_pages = r.group(2)\n    else:\n      raise Exception('No pages or data!')\n    \n    all_reports = []\n    for page in range(1, int(number_of_pages) + 1, 1):\n      page_reports = self.get(page=page)\n      all_reports += page_reports\n\n    return int(number_of_records), all_reports\n```\n\nScraping web pages is always challenging. In this case especially, the task was a bit tedious since the different report descriptions where not following a unique pattern.\n\n```\nglobal_market_insights = GlobalMarketInsights()\nnumber_of_records, all_reports = global_market_insights.fetch_all_reports()\nprint(f\"Parsed {len(all_reports)} out of {number_of_records} report descriptions!\")\n```\n\n    Parsed 1200 out of 1964 report descriptions!\n\nNext, we add the reports to a dataframe for better presentation and easier data manipulation.\n\n```\nimport pandas as pd\n\ngmi_reports_df = pd.DataFrame(all_reports) \ngmi_reports_df.head()\n```\n\n<div>\n<table border=\"1\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>market</th>\n      <th>percentage</th>\n      <th>start</th>\n      <th>end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Food phosphate</td>\n      <td>6.0</td>\n      <td>2021</td>\n      <td>2027</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Supply Chain Analytics</td>\n      <td>16.0</td>\n      <td>2021</td>\n      <td>2027</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cooking Coconut Milk</td>\n      <td>8.5</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Steel Rebar</td>\n      <td>4.0</td>\n      <td>2021</td>\n      <td>2027</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2,5-Dimethyl-2,4-Hexadiene</td>\n      <td>2.5</td>\n      <td>2021</td>\n      <td>2027</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\nSo far, so good! Let's try to sort by percentage and see which sector is projected to perform more than 30% the following years.\n\n```\nsector_projection_ascending = gmi_reports_df.sort_values('percentage', ascending=False)\nsector_projection_ascending.loc[(sector_projection_ascending['percentage']>30) & (sector_projection_ascending['start']>=2020)]\n```\n\n<div>\n<table border=\"1\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>market</th>\n      <th>percentage</th>\n      <th>start</th>\n      <th>end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>435</th>\n      <td>SD-WAN</td>\n      <td>60.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>575</th>\n      <td>Cannabidiol (CBD)</td>\n      <td>52.7</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>393</th>\n      <td>(Light Fidelity) Li-Fi</td>\n      <td>50.0</td>\n      <td>2020</td>\n      <td>2030</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Healthcare Artificial Intelligence</td>\n      <td>43.7</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>Automotive Subscription Services</td>\n      <td>40.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>964</th>\n      <td>AI in Manufacturing</td>\n      <td>40.0</td>\n      <td>2020</td>\n      <td>2025</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>Artificial Intelligence (AI) in BFSI</td>\n      <td>40.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>Robotic Process Automation</td>\n      <td>40.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>207</th>\n      <td>Fuel Cell Electric Vehicle</td>\n      <td>38.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>637</th>\n      <td>AI in Automotive</td>\n      <td>35.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>503</th>\n      <td>Artificial Intelligence Chipsets</td>\n      <td>35.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>Total Knee Replacement</td>\n      <td>34.7</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>Vaginal Rejuvenation</td>\n      <td>33.7</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>Carbon Wheels</td>\n      <td>32.3</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\nIt is becoming pretty obvious that everything around Artificial Intelligence yields the best projections, and is an attractive area for investments :)\n"},"nextPost":null},"tags":[{"id":"python","name":"python","image":"python-header.png","description":"Python is very handy in investing","color":"bg-green-300","icon":"python.svg","slug":"python","count":5},{"id":"statistics","name":"statistics","image":"statistics.jpg","description":"Statistics is the discipline that concerns the collection, organization, analysis, interpretation and presentation of data. - Wikipedia","color":"bg-green-300","icon":"statistics.svg","slug":"statistics","count":4}],"sortedTopics":[{"id":"mathematics","name":"Mathematics","image":"mathematics.png","description":"Investing, as part of the Science of Finance, is subject to the lows of Mathematics!","color":"bg-green-300","slug":"mathematics","count":4},{"id":"investing","name":"Investing","image":"investing.png","description":"The piggy bank digests a good amount of the savings! There is only one way to get away ... investing. BUT, there is a hidden enemy, Speculation!","color":"bg-green-300","slug":"investing","count":3},{"id":"automation","name":"Automation","image":"automation.jpg","description":"Spending time to do the same thing over and over again is tedious! Thus, I like to automate as much as possible.","color":"bg-green-300","slug":"automation","count":1}],"allTopics":[{"id":"mathematics","name":"Mathematics","image":"mathematics.png","description":"Investing, as part of the Science of Finance, is subject to the lows of Mathematics!","color":"bg-green-300"},{"id":"automation","name":"Automation","image":"automation.jpg","description":"Spending time to do the same thing over and over again is tedious! Thus, I like to automate as much as possible.","color":"bg-green-300"},{"id":"investing","name":"Investing","image":"investing.png","description":"The piggy bank digests a good amount of the savings! There is only one way to get away ... investing. BUT, there is a hidden enemy, Speculation!","color":"bg-green-300"}],"slug":"portfolio-expected-return-and-risk"},"__N_SSG":true}