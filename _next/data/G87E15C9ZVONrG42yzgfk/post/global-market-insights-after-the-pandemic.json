{"pageProps":{"postData":{"frontmatter":{"title":"Global Market Insights after the Pandemic.","description":"What are the projections after the Pandemic? Let's explore ...","date":"January 21, 2021","topic":{"id":"investing","name":"Investing","image":"investing.png","description":"The piggy bank digests a good amount of the savings! There is only one way to get away ... investing. BUT, there is a hidden enemy, Speculation!","color":"bg-green-300"},"tags":[{"id":"python","name":"python","image":"python-header.png","description":"Python is very handy in investing","color":"bg-green-300","icon":"python.svg"}],"author":{"id":"chris","name":"Chris","image":"https://s.gravatar.com/avatar/db809ecfa64d56da4bd9704c8393005a?s=80","description":"Software Engineer, passionate about ..."},"img":"/static/after-covid-19.jpeg","colab":"https://colab.research.google.com/drive/1nPyDupJHidnP5DLfAEKX3eYiY-MHCDmM?usp=sharing"},"post":{"content":"\n2020 was a difficult year and most of the market segments diverged from the projections! With the new facts at hand, and the emerging needs after the pandemic, we should expect changes in the market.\n\nBelow is an attempt to get a feeling of the emerging sectors by analyzing some [Global Market Insights](https://www.gminsights.com/) reports.\n\nAnd as always, let's automate ...\n\n```\n!pip install requests beautifulsoup4\nimport requests\nimport re\nfrom bs4 import BeautifulSoup\nimport string\n\nclass GlobalMarketInsights:\n  __DEFAULT_BASE_URL = 'https://www.gminsights.com/industry-reports'\n  \n  @staticmethod\n  def _escape(input):\n    printable = string.ascii_letters + string.digits + string.punctuation + ' '\n    return ''.join(c if c in printable else ' ' for c in input )\n\n  def _description_matcher(self, descr):\n    descr = GlobalMarketInsights._escape(descr.replace('\\t', ' ').replace('\\n', ' ').replace('\\r', ' '))\n\n    start_date = end_date = percentage = market_name = None\n\n    r1 = re.search('^(.*) (?:Market|Aftermarket) .*$', descr, re.IGNORECASE)\n    if r1:\n      market_name = r1.group(1).strip()\n\n    r2 = re.search('.* between (\\d+) (?:and|to) (\\d+)', descr)\n    if r2:\n      start_date = r2.group(1).strip()\n      end_date = r2.group(2).strip()\n    \n    r3 = re.search('.* (?:from|of) (\\d+) to (\\d+)', descr)\n    if r3:\n      start_date = r3.group(1).strip()\n      end_date = r3.group(2).strip()\n    \n    r4 = re.search('([-+]?\\d*\\.\\d+|\\d+)%', descr)\n    if r4:\n      percentage = r4.group(1)\n    \n    if None in (market_name, percentage, start_date, end_date):\n      raise Exception(f\"Couldn't parse: {descr}\")\n    else:\n      return {\n        \"market\": market_name,\n        \"percentage\" : float(percentage),\n        \"start\": int(start_date),\n        \"end\": int(end_date)\n      }\n\n  def get(self, page=1):\n    page = requests.get(f\"{GlobalMarketInsights.__DEFAULT_BASE_URL}?page={page}\")\n    soup = BeautifulSoup(page.text, 'html.parser')\n    single_rds = soup.find_all('div', class_='single_rd')\n    reports = []\n    for single_rd in single_rds:\n      single_rd_children = single_rd.findChildren()\n      for single_rd_child in single_rd_children:\n        if single_rd_child.has_attr('class') and single_rd_child['class'][0] == 'rd_desc':\n          description = single_rd_child.getText()\n          try:\n            reports.append(self._description_matcher(description))\n          except Exception as e:\n            # print(e)\n            pass\n          break\n    return reports\n  \n  def fetch_all_reports(self):\n    # get the total number of pages and start iterating\n    page = requests.get(f\"{GlobalMarketInsights.__DEFAULT_BASE_URL}?page=1\")\n    lun_q = 'Displaying \\d+ records out of (\\d+) on Page \\d+ of (\\d+)'\n    r = re.search(lun_q, page.text)\n    if r:\n        number_of_records = r.group(1)\n        number_of_pages = r.group(2)\n    else:\n      raise Exception('No pages or data!')\n    \n    all_reports = []\n    for page in range(1, int(number_of_pages) + 1, 1):\n      page_reports = self.get(page=page)\n      all_reports += page_reports\n\n    return int(number_of_records), all_reports\n```\n\nScraping web pages is always challenging. In this case especially, the task was a bit tedious since the different report descriptions where not following a unique pattern.\n\n```\nglobal_market_insights = GlobalMarketInsights()\nnumber_of_records, all_reports = global_market_insights.fetch_all_reports()\nprint(f\"Parsed {len(all_reports)} out of {number_of_records} report descriptions!\")\n```\n\n    Parsed 1200 out of 1964 report descriptions!\n\nNext, we add the reports to a dataframe for better presentation and easier data manipulation.\n\n```\nimport pandas as pd\n\ngmi_reports_df = pd.DataFrame(all_reports) \ngmi_reports_df.head()\n```\n\n<div>\n<table border=\"1\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>market</th>\n      <th>percentage</th>\n      <th>start</th>\n      <th>end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Food phosphate</td>\n      <td>6.0</td>\n      <td>2021</td>\n      <td>2027</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Supply Chain Analytics</td>\n      <td>16.0</td>\n      <td>2021</td>\n      <td>2027</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cooking Coconut Milk</td>\n      <td>8.5</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Steel Rebar</td>\n      <td>4.0</td>\n      <td>2021</td>\n      <td>2027</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2,5-Dimethyl-2,4-Hexadiene</td>\n      <td>2.5</td>\n      <td>2021</td>\n      <td>2027</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\nSo far, so good! Let's try to sort by percentage and see which sector is projected to perform more than 30% the following years.\n\n```\nsector_projection_ascending = gmi_reports_df.sort_values('percentage', ascending=False)\nsector_projection_ascending.loc[(sector_projection_ascending['percentage']>30) & (sector_projection_ascending['start']>=2020)]\n```\n\n<div>\n<table border=\"1\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>market</th>\n      <th>percentage</th>\n      <th>start</th>\n      <th>end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>435</th>\n      <td>SD-WAN</td>\n      <td>60.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>575</th>\n      <td>Cannabidiol (CBD)</td>\n      <td>52.7</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>393</th>\n      <td>(Light Fidelity) Li-Fi</td>\n      <td>50.0</td>\n      <td>2020</td>\n      <td>2030</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Healthcare Artificial Intelligence</td>\n      <td>43.7</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>Automotive Subscription Services</td>\n      <td>40.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>964</th>\n      <td>AI in Manufacturing</td>\n      <td>40.0</td>\n      <td>2020</td>\n      <td>2025</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>Artificial Intelligence (AI) in BFSI</td>\n      <td>40.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>Robotic Process Automation</td>\n      <td>40.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>207</th>\n      <td>Fuel Cell Electric Vehicle</td>\n      <td>38.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>637</th>\n      <td>AI in Automotive</td>\n      <td>35.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>503</th>\n      <td>Artificial Intelligence Chipsets</td>\n      <td>35.0</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>Total Knee Replacement</td>\n      <td>34.7</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>Vaginal Rejuvenation</td>\n      <td>33.7</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>Carbon Wheels</td>\n      <td>32.3</td>\n      <td>2020</td>\n      <td>2026</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\nIt is becoming pretty obvious that everything around Artificial Intelligence yields the best projections, and is an attractive area for investments :)\n","excerpt":""},"previousPost":{"slug":"are-stock-returns-normally-distributed","frontmatter":{"title":"Are Stock Returns Normally Distributed?","description":"What do you think?","date":"December 20, 2020","topic":{"id":"investing","name":"Investing","image":"investing.png","description":"The piggy bank digests a good amount of the savings! There is only one way to get away ... investing. BUT, there is a hidden enemy, Speculation!","color":"bg-green-300"},"tags":[{"id":"python","name":"python","image":"python-header.png","description":"Python is very handy in investing","color":"bg-green-300","icon":"python.svg"}],"author":{"id":"chris","name":"Chris","image":"https://s.gravatar.com/avatar/db809ecfa64d56da4bd9704c8393005a?s=80","description":"Software Engineer, passionate about ..."},"img":"/static/normal-dist-with-hist.png","colab":"https://colab.research.google.com/drive/1iYrNJ9ISktohy1dG2s16_FZKakB8FLU5?usp=sharing"},"excerpt":"","content":"\nIn a previous post we talked about the [Higher Moments of a Distribution](/post/higher-moments-of-a-distribution). We saw that skewness and kurtosis are two attributes that can identify if a distribution is normal or not (skewnes = 0 & kurtosis = 3).\n\nLet's try this approach on the MSFT's stock.\n\n\n```\n%pip install yahoofinancials\nfrom yahoofinancials import YahooFinancials\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport dateutil.parser\nimport numpy as np\n\nmatplotlib.rcParams['figure.figsize'] = (10.0, 5.0)\nmatplotlib.style.use('ggplot')\n\ndef retrieve_stock_data(ticker, start, end):\n    json = YahooFinancials(ticker).get_historical_price_data(start, end, \"daily\")\n    columns=[\"adjclose\"]  # [\"open\",\"close\",\"adjclose\"]\n    df = pd.DataFrame(columns=columns)\n    for row in json[ticker][\"prices\"]:\n        d = dateutil.parser.isoparse(row[\"formatted_date\"])\n        df.loc[d] = [row[\"adjclose\"]] # [row[\"open\"], row[\"close\"], row[\"adjclose\"]]\n    df.index.name = \"date\"\n    return df\n\ndef normal_rets(S):\n    return S.pct_change().dropna()\n\ndef log_rets(S):\n    rets = np.log(S) - np.log( S.shift(1))\n    return rets[1:]\n\nstock_prices = retrieve_stock_data(\"MSFT\", \"2000-01-01\", \"2020-01-01\")\n\nrets = normal_rets(stock_prices).dropna()\nrets.columns = ['returns']\nrets.plot(figsize=(14,7))\nplt.title(\"Daily returns\", weight=\"bold\");\n```\n  \n![png](are-stock-returns-normally-distributed/are-stock-returns-normally-distributed-1-1.png)\n\nLet's print skewness and kurtosis:\n\n```\nfrom scipy.stats import kurtosis, skew\nskew(rets, bias=False)[0], kurtosis(rets, bias=False, fisher=False)[0]\n```\n\n    (0.20887713542026032, 13.229622042763442)\n\nIt is obvious that the MSFT stock returns for that period follow a leptokurtic distribution and are far from normal. Same, of course, happens if we get the log returns instead.\n\n```\nlog_msft_rets = log_rets(stock_prices).dropna()\nskew(log_msft_rets, bias=False)[0], kurtosis(log_msft_rets, bias=False, fisher=False)[0]\n```\n\n    (-0.12981025399984283, 12.81366131030108)\n\n## Normality Tests\n\nThere are several interrelated approaches to determining normality.\n\n1. Histogram with the normal curve superimposed. Unfortunately, there is no automated way to represent the \"fitness\" as a value. This approach is empirical mostly and requires experience.\n\n2. Skewness & Kurtosis Tests.\n\n3. Normality plots. “Normal Q-Q Plot” provides a graphical way to determine the level of normality.\n\n4. Normality tests. The Kolmogorov-Smirnov test (K-S) and Shapiro-Wilk (S-W) test are designed to test normality by comparing your data to a normal distribution with the same mean and standard deviation of your sample. If the test is NOT significant, then the data are normal, so any value above .05 indicates normality. If the test is significant (less than .05), then the data are non-normal.\n\n### Histogram & Normal PDF\n\n```\nfrom scipy.stats import norm\nx = np.linspace(min(rets.returns.values), max(rets.returns.values))\nax = rets.plot(kind='hist', bins=500, density=True)\npdf_fitted = norm.pdf(x, *norm.fit(rets.returns.values))\npd.Series(pdf_fitted, x).plot(ax=ax)\nplt.show()\n```\n    \n![png](are-stock-returns-normally-distributed/are-stock-returns-normally-distributed-8-0.png)\n\n### Skewness & Kurtosis Tests\n\n```\nfrom scipy import stats\nstats.kurtosistest(rets.returns)\n```\n\n    KurtosistestResult(statistic=29.93227785492693, pvalue=7.484189304773088e-197)\n\n```\nstats.skewtest(rets.returns)\n```\n\n    SkewtestResult(statistic=5.99114785753993, pvalue=2.083650895527666e-09)\n\n### QQ-Plot\n\n```\nfrom numpy.random import seed\nfrom statsmodels.graphics.gofplots import qqplot\nfrom matplotlib import pyplot\nseed(1)\nqqplot(rets.returns, line='s')\npyplot.show()\n```\n    \n![png](are-stock-returns-normally-distributed/are-stock-returns-normally-distributed-13-0.png)\n    \n\nThe Quantile-Quantile plot, as the name suggests, will compare the quantiles between the normal distribution and our data. We notice here that, the tails of the distribution of our data are diverging a lot from the normal distribution. This is what we would expect. Fat tails!\n\n### Statistical Normality Tests\n\nThe tests assume that that the sample was drawn from a Gaussian distribution. Technically this is called the null hypothesis, or H0. A threshold level is chosen called alpha, typically 5% (or 0.05), that is used to interpret the p-value.\n\nIn the SciPy implementation of these tests, you can interpret the p value as follows.\n\n* p <= alpha: reject H0, not normal.\n* p > alpha: fail to reject H0, normal.\n\nThis means that, in general, we are seeking results with a larger p-value to confirm that our sample was likely drawn from a Gaussian distribution.\n\nA result above 5% does not mean that the null hypothesis is true. It means that it is very likely true given available evidence. The p-value is not the probability of the data fitting a Gaussian distribution; it can be thought of as a value that helps us interpret the statistical test.\n\n#### Kolmogorov-Smirnov test (K-S)\n\n\n```\nkstest = stats.kstest(rets.returns, 'norm')\nkstest.pvalue > 0.05\n```\n\n    False\n\n#### Shapiro-Wilk Test\n\n```\nshapiro_stat, shapiro_p = stats.shapiro(rets.returns)\nshapiro_p > 0.05\n```\n\n    False\n\n\n#### D’Agostino’s K^2 Test\n\nThe D’Agostino’s K^2 test calculates summary statistics from the data, namely kurtosis and skewness, to determine if the data distribution departs from the normal distribution, named for Ralph D’Agostino.\n\n* Skew is a quantification of how much a distribution is pushed left or right, a measure of asymmetry in the distribution.\n* Kurtosis quantifies how much of the distribution is in the tail.\n\nIt is a simple and commonly used statistical test for normality.\n\n```\nseed(1)\ndagostino_stat, dagostino_p = stats.normaltest(rets.returns)\ndagostino_p > 0.05\n```\n\n    False\n\n#### Jarque-Bera Test for Normality\n\n```\njarque_bera_stat, jarque_bera_p = stats.jarque_bera(rets.returns)\njarque_bera_p > 0.05\n```\n\n    False\n\n## Conclusion\n\nIn this post we went through some techniques that allow us identify if stock returns are normally distributed. We saw, with an example, that returns (arithmetic, or log) are not normally distributed but instead exhibit fat tails. I cannot generalize of course by only one example that I provide here, but I will leave that as a small exercise to the curious readers.\n\nThe question that is now left is? Since the (I could event say here, financial asset returns (everything that is publicly traded)) returns are not following a normal distribution, that what type of distribution they follow?\n\nThe answer to that ... in a later article! :)\n"},"nextPost":null},"tags":[{"id":"python","name":"python","image":"python-header.png","description":"Python is very handy in investing","color":"bg-green-300","icon":"python.svg","slug":"python","count":5},{"id":"statistics","name":"statistics","image":"statistics.jpg","description":"Statistics is the discipline that concerns the collection, organization, analysis, interpretation and presentation of data. - Wikipedia","color":"bg-green-300","icon":"statistics.svg","slug":"statistics","count":3}],"sortedTopics":[{"id":"mathematics","name":"Mathematics","image":"mathematics.png","description":"Investing, as part of the Science of Finance, is subject to the lows of Mathematics!","color":"bg-green-300","slug":"mathematics","count":4},{"id":"investing","name":"Investing","image":"investing.png","description":"The piggy bank digests a good amount of the savings! There is only one way to get away ... investing. BUT, there is a hidden enemy, Speculation!","color":"bg-green-300","slug":"investing","count":2},{"id":"automation","name":"Automation","image":"automation.jpg","description":"Spending time to do the same thing over and over again is tedious! Thus, I like to automate as much as possible.","color":"bg-green-300","slug":"automation","count":1}],"allTopics":[{"id":"mathematics","name":"Mathematics","image":"mathematics.png","description":"Investing, as part of the Science of Finance, is subject to the lows of Mathematics!","color":"bg-green-300"},{"id":"automation","name":"Automation","image":"automation.jpg","description":"Spending time to do the same thing over and over again is tedious! Thus, I like to automate as much as possible.","color":"bg-green-300"},{"id":"investing","name":"Investing","image":"investing.png","description":"The piggy bank digests a good amount of the savings! There is only one way to get away ... investing. BUT, there is a hidden enemy, Speculation!","color":"bg-green-300"}],"slug":"global-market-insights-after-the-pandemic"},"__N_SSG":true}